# Hey its me, Jyoti, working here
 importing library

import os
import numpy as np
import pandas as pd
import seaborn as sns


# Increase the print output

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)


os.chdir("C:\\Users\\hp\\Documents\\DaTa sci\\Project Data\\Finance DS")

# Read the data
fullRaw=pd.read_csv("finance_train.csv")
fullRaw.head()



fullRaw.head()
# Check for NAs
fullRaw.isnull().sum()

# Let us check the counts of 1's & 2's count in dataset
fullRaw['Revenue.Grid'].value_counts()

# % Split of 1s and 2s
fullRaw['Revenue.Grid'].value_counts()/ fullRaw.shape[0]

#fullRaw['Revenue.Grid'].value_counts(normalize=True)

# Summarize the data
fullRaw_Summary = fullRaw.describe()
# fullRaw_Summary = fullRaw.describe(include = "all")
fullRaw_Summary

# Lets drop 'Customer ID' column from the data as it is not going to assist us in our model
fullRaw.drop(['REF_NO'], axis = 1, inplace = True) 
fullRaw.shape



# Categorical variables: Gender, Academic_Qualification, Marital


variableToUpdate = 'children'
fullRaw[variableToUpdate].value_counts() # To check the unique categories of the variable
fullRaw[variableToUpdate].replace({1:"Single Child", 
                                     2:"Two Children",
                                     3:"Three Children",
                                     'Zero':"No Child"},inplace=True)
fullRaw[variableToUpdate].value_counts()

# Dummy variable creation
############################
fullRaw2 = pd.get_dummies(fullRaw, drop_first = True) # 'Source'  column will change to 'Source_Train' and it contains 0s and 1s
fullRaw2.shape

# Add Intercept Column
############################

# In Python, logistic regression function does NOT account for an intercept.
# So, we need to specify a column which has a constant value of 1 
from statsmodels.api import add_constant
fullRaw2 = add_constant(fullRaw2)
fullRaw2.shape



















######################################################################
# test data
# Read the data
Raw=pd.read_csv("finance_test.csv")
Raw.head()



fullRaw.head()
# Check for NAs
fullRaw.isnull().sum()

# Let us check the counts of 1's & 2's count in dataset
fullRaw['Revenue.Grid'].value_counts()

# % Split of 1s and 2s
fullRaw['Revenue.Grid'].value_counts()/ fullRaw.shape[0]

#fullRaw['Revenue.Grid'].value_counts(normalize=True)

# Summarize the data
fullRaw_Summary = fullRaw.describe()
# fullRaw_Summary = fullRaw.describe(include = "all")
fullRaw_Summary

# Lets drop 'Customer ID' column from the data as it is not going to assist us in our model
fullRaw.drop(['REF_NO'], axis = 1, inplace = True) 
fullRaw.shape



# Categorical variables: Gender, Academic_Qualification, Marital


variableToUpdate = 'children'
fullRaw[variableToUpdate].value_counts() # To check the unique categories of the variable
fullRaw[variableToUpdate].replace({1:"Single Child", 
                                     2:"Two Children",
                                     3:"Three Children",
                                     'Zero':"No Child"},inplace=True)
fullRaw[variableToUpdate].value_counts()

# Dummy variable creation
############################
fullRaw2 = pd.get_dummies(fullRaw, drop_first = True) # 'Source'  column will change to 'Source_Train' and it contains 0s and 1s
fullRaw2.shape

# Add Intercept Column
############################

# In Python, logistic regression function does NOT account for an intercept.
# So, we need to specify a column which has a constant value of 1 
from statsmodels.api import add_constant
fullRaw2 = add_constant(fullRaw2)
fullRaw2.shape
